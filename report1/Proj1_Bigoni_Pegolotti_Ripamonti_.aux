\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{bci_ii}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Visualisation}{1}{section.2}}
\newlabel{sec_visual}{{2}{1}{Data Visualisation}{section.2}{}}
\citation{bci_ii}
\citation{schirrmeister2017deep}
\citation{goodfellow2016deep}
\citation{savgol}
\citation{goodfellow2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of training and test datasets averages per channel over 316 and 100 samples, respectively. Three channels (i.e., 3, 10 and 25) are randomly chosen, but the results generalise to all. Each plot shows the mean of the samples with output 0 (i.e., classified as ``right'') and those with output 1 (i.e., classified as ``left''). The means of the signals sampled with 1000 Hz are plotted in red and blue, while those of the signals downsampled to 100 Hz ar plotted in black and magenta. For some channels (e.g., channel 3) the down-sampled averages present a lower variability than those for the signals sampled at 1000 Hz. In all cases, the averages of the training set are distinctively different from those of the test set. }}{2}{figure.1}}
\newlabel{fig_mean_1000hz_vs_downsampled}{{1}{2}{Comparison of training and test datasets averages per channel over 316 and 100 samples, respectively. Three channels (i.e., 3, 10 and 25) are randomly chosen, but the results generalise to all. Each plot shows the mean of the samples with output 0 (i.e., classified as ``right'') and those with output 1 (i.e., classified as ``left''). The means of the signals sampled with 1000 Hz are plotted in red and blue, while those of the signals downsampled to 100 Hz ar plotted in black and magenta. For some channels (e.g., channel 3) the down-sampled averages present a lower variability than those for the signals sampled at 1000 Hz. In all cases, the averages of the training set are distinctively different from those of the test set}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Models we considered}{2}{section.3}}
\newlabel{sec_allmodel}{{3}{2}{Models we considered}{section.3}{}}
\citation{zheng2014time}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of few randomly chosen samples from training and test datasets for channels 3, 10 and 25. Samples classified as 0 (i.e., ``right'') are plotted in red, while samples classified as 1 (i.e., ``left'') are plotted in blue. The down-sampled averages corresponding to the training and test dataset are also shown in black. These plots confirm that the data have a high variability. }}{3}{figure.2}}
\newlabel{fig_fewsamples_vs_mean_downsampled}{{2}{3}{Plot of few randomly chosen samples from training and test datasets for channels 3, 10 and 25. Samples classified as 0 (i.e., ``right'') are plotted in red, while samples classified as 1 (i.e., ``left'') are plotted in blue. The down-sampled averages corresponding to the training and test dataset are also shown in black. These plots confirm that the data have a high variability}{figure.2}{}}
\citation{schirrmeister2017deep}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Test errors for the linear perceptron (M1), the simple convolutional neural network (M2), the multichannel deep convolutional neural network combined with the linear perceptron (M3) and the shallow convolutional neural network (M4).}}{4}{table.1}}
\newlabel{tab_results}{{3}{4}{Models we considered}{table.1}{}}
\bibstyle{abbrv}
\bibdata{mybib_dl}
\bibcite{bci_ii}{1}
\bibcite{savgol}{2}
\bibcite{goodfellow2016deep}{3}
\bibcite{schirrmeister2017deep}{4}
\bibcite{zheng2014time}{5}
\@writefile{toc}{\contentsline {section}{\numberline {4}Model that works best}{5}{section.4}}
\newlabel{sec_themodel}{{4}{5}{Model that works best}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{5}{section.5}}
\newlabel{sec_conclusion}{{5}{5}{Conclusion}{section.5}{}}
